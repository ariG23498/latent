[
  {
    "objectID": "posts/ddpms/part3/index.html",
    "href": "posts/ddpms/part3/index.html",
    "title": "A deeper dive into DDPMs",
    "section": "",
    "text": "In the last notebook, we discussed about Gaussian Distribution, its applications in context of diffusion models, and the forward process in diffusion models. Let’s revisit the forward process equation and the corresponding code that we saw in the last notebook.\n\n1. The Forward Process\n\\[\nq(x_{1:T}\\vert x_{0})\n:= \\prod_{t=1}^{T}q(x_{t}\\vert x_{t-1})\n:=\\prod_{t=1}^{T}\\mathcal{N}(x_{t};\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t}\\bf I) \\tag{1}\n\\]\nAs a refresher, \\(q(x_{0:T})\\) is known as the forward distribution and \\(q(x_{t}\\vert x_{t-1}\\) is referred as forward diffusion kernel\n\n\nShow the code\n\ndef forward_process_ddpms(img_t_minus_1, beta, t):\n    \"\"\"Implements the forward process of a DDPM model.\n    \n    Args:\n        img_t_minus_1: Image at the previous timestep (t - 1)\n        beta: Scheduled Variance\n        t: Current timestep\n    Returns:\n        Image obtained at current timestep\n    \"\"\"\n    \n    # 1. Obtain beta_t. Reshape it to have the same number of\n    # dimensions as our image array\n    beta_t = beta[t].reshape(-1, 1, 1)\n    \n    # 2. Calculate mean and variance\n    mu = np.sqrt((1.0 - beta_t)) * img_t_minus_1\n    sigma = np.sqrt(beta_t)\n    \n    # 3. Obtain image at timestep t using equation (15)\n    img_t = mu + sigma * np.random.randn(*img_t_minus_1.shape)\n    return img_t\n\n\n# Let's check if ourforward process function is\n# doing what it is supposed to do on a sample image\n\n# 1. Load image using PIL (or any other library that you prefer)\nimg = Image.open(\"../images/cat.jpg\")\n\n# 2. Resize the image to desired dimensions\nIMG_SIZE = (128, 128)\nimg = img.resize(size=IMG_SIZE)\n\n# 3. Define number of timesteps\ntimesteps = 100\n\n# 4. Generate beta (variance schedule)\nbeta_start = 0.0001\nbeta_end = 0.05\nbeta = np.linspace(beta_start, beta_end, num=timesteps, dtype=np.float32)\n\n\nprocessed_images = []\nimg_t = np.asarray(img.copy(), dtype=np.float32) / 255.\n\n# 5. Run the forward process to obtain img after t timesteps\nfor t in range(timesteps):\n    img_t = forward_process_ddpms(img_t_minus_1=img_t, beta=beta, t=t)\n    if t%20==0 or t==timesteps - 1:\n        sample = (img_t.clip(0, 1) * 255.0).astype(np.uint8)\n        processed_images.append(sample)\n\n# 6. Plot and see samples at different timesteps\n_, ax = plt.subplots(1, len(processed_images), figsize=(15, 6))\n\nfor i, sample in enumerate(processed_images):\n    ax[i].imshow(sample)\n    ax[i].set_title(f\"Timestep: {i*20}\")\n    ax[i].axis(\"off\")\n    ax[i].grid(False)\n\nplt.suptitle(\"Forward process in DDPMs\", y=0.75)\nplt.show()\nplt.close()\n\n\nCan you spot a major problem with the above equation? (Hint: Check the loop)\nDon’t worry if you didn’t get it. Look at the above code closely. Forget everything from the modelling perspective except for the forward pass. You will notice that to obtain a noisy sample, say at timestep t, we need to iterate from t0 to t-1. Why? Because the sample obtained at each timestep is conditioned on the samples from the previous timesteps.\nThat’s not efficient. What if there are 1000 steps and you want to sample the 999th timestep? You will iterate the whole loop, simulating the entire Markov Chain. Now that we know the problem, we should think about how we can do better.\n\n\n2. Reparameterization\nWe know that sum of the independent Gaussians is still a Gaussian. We can leverage this fact to sample from an arbitrary forward step. All we need to do is apply the reparameterization trick.\nLet   \\(\\alpha_{t} = 1 - \\beta_{t},\\)   and   \\(\\bar{\\alpha}_{t} = \\prod_{i=1}^T \\alpha_{i}\\)\nFrom equation (1) we know that:\n\\[\nq(x_{1:T}\\vert x_{0}) := \\prod_{t=1}^{T}q(x_{t}\\vert x_{t-1}) :=\\prod_{t=1}^{T}\\mathcal{N}(x_{t};\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t} \\bf{I}) \\\\\n\\]\n\\[\n\\text{or} \\ \\ q(x_{t}\\vert x_{t-1}) = \\mathcal{N}(x_{t};\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t} \\bf{I})\n\\]\nWe can obtain the sample at timestep t as:\n\\[\nx_{t} = \\sqrt{1 - \\beta_{t}} x_{t-1} +  \\sqrt{\\beta_{t}}\\epsilon_{t-1}; \\ \\ \\text where \\ \\  \\epsilon_{t-1} \\sim \\mathcal{N}(0, \\bf{I})\n\\]\nReplacing \\(\\beta\\) with \\(\\alpha\\) in the above equation we can obtain sample at timestep t as:\n\\[\n\\begin{align*}\nx_{t} &= \\sqrt{\\alpha_{t}} x_{t-1} + \\sqrt{1 - \\alpha_{t}}\\epsilon_{t-1} \\\\\n\\Rightarrow x_{t} &=\n\\sqrt{\\alpha_{t}} \\ \\ \\underbrace{(\\sqrt{\\alpha_{t-1}} x_{t-2} + \\sqrt{1 - \\alpha_{t-1}}\\epsilon_{t-2})}_{\\text{( Expanding } x_{t-1})} +\n\\sqrt{1 - \\alpha_{t}}\\epsilon_{t-1} \\\\ \\\\\n&= \\sqrt{\\alpha_{t} \\alpha_{t-1}} x_{t-2} +\n\\underbrace{\\sqrt{\\alpha_{t}(1 - \\alpha_{t-1})}\\epsilon_{t-2}}_{\\text{RV1}} +\n\\underbrace{\\sqrt{1 - \\alpha_{t}}\\epsilon_{t-1}}_{\\text{RV2}} \\\\\n\\end{align*}\n\\]\nThe two terms namely RV1, and RV2 on RHS in the above equation are two random variables distributed normally with a mean of zero and variances \\(\\alpha_{t}(1 - \\alpha_{t-1})\\ \\), and \\((1 - \\alpha_{t})\\) respectively.\nIn the last lesson we learned that if we have two Gaussian distributions with mean values \\(\\mu_{1} , \\mu_{2}\\) and variances \\(\\sigma_{1}^2 , \\sigma_{2}^2\\) respectively, then the sum of these two random variables is equivaluent to another random variable with a normal distribution \\(\\mathcal{N}(\\mu_{1} + \\mu_{2}, \\sigma_{1}^2 +\\sigma_{2}^2)\\). Applying this to the above equation yields:\n\\[\n\\begin{align*}\n\\Rightarrow x_{t} &=\n\\sqrt{\\alpha_{t} \\alpha_{t-1}} x_{t-2} +\n\\sqrt{\\alpha_{t}(1 - \\alpha_{t-1}) +\n(1 - \\alpha_{t})}\\bar{z}_{t-2} & \\bar{z}_{t-2} \\ \\text {is the merged Gaussian} \\\\\n&= \\sqrt{\\alpha_{t} \\alpha_{t-1}} x_{t-2} +\n\\sqrt{1 - \\alpha_{t} \\alpha_{t-1}}\\bar{z}_{t-2} \\\\\n&= \\ \\ ... \\\\\n\\Rightarrow x_{t}&= \\sqrt{\\bar{\\alpha_{t}}} x_{0} +\n\\sqrt{1 - \\bar{\\alpha_{t}}}\\epsilon \\ \\  \\ \\text{ (since } \\\n\\ \\bar{\\alpha}_{t} = \\prod_{i=1}^T \\alpha_{i})\n\\end{align*}\n\\]\nFrom above, we can say that:\n\\[\nq(x_{t}\\vert x_{0}) = \\mathcal{N}(x_{t};\\sqrt{\\bar{\\alpha_{t}}} x_{0},\\ (1 - \\bar{\\alpha_{t}}) \\ \\bf{I}) \\tag {2}\n\\]\nHa! The above equation is nice.Given the original image, we can now sample at any arbitrary timestep without simulating the entire Markov chain till that step. Before coding it up, let’s recap of what we did and achieve:\n\nWe figured out that in the original formulation, we need to simulate the Markov chain to the step for which we want to sample.\nWe reparameterized \\(\\beta\\) in terms of \\(\\alpha\\)\nThe above reparameterization leads to an equation where we can sample at any arbitrary timestep\n\nLet’s code it and compare the results with the previous results\n\n\nShow the code\n\ndef forward_process_ddpms_v2(orig_img, alpha_bar, t):\n    \"\"\"Implements the efficient forward process of a DDPM model.\n    \n    Args:\n        orig_img: Image at timestep t=0\n        alpha_bar: The reparameterized version of beta\n        t: Current timestep\n    Returns:\n        Image obtained at current timestep\n    \"\"\"\n    \n    # 1. Obtain beta_t. Reshape it to have the same number of\n    # dimensions as our image array\n    alpha_bar_t = alpha_bar[t].reshape(-1, 1, 1)\n    \n    # 2. Calculate mean and variance\n    mu = np.sqrt(alpha_bar_t) * orig_img\n    sigma = np.sqrt(1.0 - alpha_bar_t)\n    \n    # 3. Obtain image at timestep t\n    img_t = mu + sigma * np.random.randn(*orig_img.shape)\n    return img_t\n\n\n\n# 1. Define alpha and alpha_bar\nalpha = 1.0 - beta\nalpha_bar = np.cumprod(alpha)\n\n\nprocessed_images = [img] # Image at 0th step\norig_img = np.asarray(img.copy(), dtype=np.float32) / 255.\n\n\n# 2. Run the forward pass for specific timesteps\n# We will use the timesteps we used in previous visualizations\nspecific_timesteps = [19, 39, 59, 79, 99]\nfor step in specific_timesteps:\n    img_t = forward_process_ddpms_v2(orig_img, alpha_bar, step)\n    img_t = (img_t.clip(0, 1) * 255.0).astype(np.uint8)\n    processed_images.append(img_t)\n\n    \n# 3. Plot and see samples at different timesteps\n_, ax = plt.subplots(1, len(processed_images), figsize=(15, 6))\n\nfor i, sample in enumerate(processed_images):\n    ax[i].imshow(sample)\n    ax[i].set_title(f\"Timestep: {i*20}\")\n    ax[i].axis(\"off\")\n    ax[i].grid(False)\n\nplt.suptitle(\"Efficient Forward process in DDPMs\", y=0.75)\nplt.axis(\"off\")\nplt.savefig(\"../plots/efficient_forward_process.png\",\n            pad_inches=0,\n            bbox_inches='tight'\n           )\nplt.show()\nplt.close()\n\n\nNow that we are aware of everything involved in the forward process, we need to figure out how are we going to generate image from the noise we got at the end of the forward process.\n\n\n3. The Reverse Process\nWe should end up with a pure noise distribution by the end of the forward process, given we set the variance schedule appropriately i.e. the distribution we will end up with will be \\(\\sim \\mathcal{N}(x_{T}; 0,I)\\). For the reverse process, we will start with noise, and will try to undo the noise at each timestep to obtain back the original image. We can write this process as:\n\\[\np_{\\theta}(x_{0:T})\n:= p(x_{T}) \\prod_{t=1}^T p_{\\theta}(x_{t-1} | x_{t})\n:= p(x_{T}) \\prod_{t=1}^T \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t)) \\tag{3}\n\\]\nwhere the parameters of the multivariate Gaussian are time-dependent and are to be learned.\nA few things to note:\n\n\\(p(x_{0:T})\\) is the reverse distribution and \\(p(x_{t-1} | x_{t})\\) is known as the reverse diffusion kernel\n\\(\\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}\\) are the learnable parameters of the reverse distribution\nThe forward process can be seen as pushing the sample off the data mainfold, turning it into noise. The reverse process can be seen as pushing the sample back to the manifold by removing the noise. (Words taken from Ari Seff’s tutorial because I don’t think there is any better way to put it.)\n\\(p(x_{T})\\) is nothing but \\(q(x_{T})\\) i.e. the point where the forward process ends is the starting point of the reverse process.\nThere can be n number of pathways to arrive at a sample \\(p_{\\theta}(x_{0})\\) starting from a noise sample. To obtain \\(p_{\\theta}(x_{0})\\), we would then be required to integrate over all the possible pathways i.e. \\(p_{\\theta}(x_{0}) = \\int p_{\\theta}(x_{0:T})dx_{1:T}\\)\nCalculating density like in the above step is intractable. A neural network is sufficient to predict the mean \\(\\mu_{\\theta}\\) and the diagonal covariance matrix \\(\\Sigma_{\\theta}\\) for the reverse process as shown below in the equation, but we would also be required to frame our objectve function differently\n\n\n\n4. The Training Objective\nLet’s write down all the equations we saw for the reverse process, again before we move to the discussion on training objective.\n\\[\n\\begin{align*}\np_{\\theta}(x_{0}) &= \\int p_{\\theta}(x_{0:T})dx_{1:T} \\tag{4} \\\\\np_{\\theta}(x_{t-1}|x_{t}) &:= \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t)) \\tag{5}\n\\end{align*}\n\\]\nIf eq.(4) is intractable, then how do we frame our objective function?\nIf you have worked with other types of generative models before, then you might have seen something like equation eq.(4) in other types of generative models. But where? The answer is Variational AutoEncoder(VAE for short). If we treat \\(x_{0}\\) as observed variable and \\(x_{1:T}\\) as latent variables, then we have a setup similar to a VAE.\nSimilarities:\n\nThe forward process can be seen as the equivalent of the encoder in a VAE converting data to latents\nThe reverse process can be seen as the equivalent of the decoder in a VAE producing data from latents\nGiven that the above two hold, we can maximize the lower bound (Check out this post if you need a referesher on ELBO)\n\nDifferences:\n\nUnlike a VAE where the encoder is jointly trained with the decoder, the forward process in DDPMs is fixed. Only the reverse part is trainable\nUnlike in VAEs, the latents in DDPMs have the same dimensionality as the observed variable\nVariation lower bound or Evidence lower bound (ELBO for short), in the case of DDPMs, is a sum of losses at each time step t, \\(L = L_{0} + L_{1} + ... + L_{T}\\) \n\n\nFirst, let’s write down the lower bound we see in a VAE here. Let’s say x is an observed variable, and z is the latent variable (in context of a VAE). It is known that:\n\\[\n\\begin{align*}\n&\\text{log}\\ p_{\\theta}(x) \\ge \\text{variational lower bound} \\\\\n\\Rightarrow &\\text{log}\\ p_{\\theta}(x) \\ge \\mathbb{E}_{q_{\\phi}(z|x)}[\\text{log}\\ p_{\\theta}(x|z)] \\ - \\ D_{KL}(q_{\\phi}(z|x) \\parallel p_{\\theta}(z)) \\tag{6}\n\\end{align*}\n\\]\nAs discussed earlier, when it comes to diffusion models, we can treat \\(x_{0}\\) as the observed variable, and \\(x_{1:T}\\) as the latent varaibles. Substituting these in equation (6) yields:\n\\[\n\\begin{align*}\n\\text{log}\\ p_{\\theta}(x_{0}) &\\ge \\mathbb{E}_{q(x_{1:T}|x_{0})}[\\text{log}\\ p_{\\theta}(x_{0}|x_{1:T})] \\ - \\ \\underbrace{D_{KL}(q(x_{1:T}|x_{0}) \\parallel p_{\\theta}(x_{1:T}))} \\\\ \\\\\n&=\\mathbb{E}_{q(x_{1:T}|x_{0})}[\\text{log}\\ p_{\\theta}(x_{0}|x_{1:T})] \\ - \\ \\mathbb{E}_{q(x_{1:T}|x_{0})}\\big[\\text{log}\\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{1:T})}\\big] \\\\\n&=\\mathbb{E}_{q}[\\text{log}\\ p_{\\theta}(x_{0}|x_{1:T})] \\ - \\\n\\mathbb{E}_{q} \\big[ \\text{log}\\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{1:T})} \\big]\n\\\\\n&=\\mathbb{E}_{q}\\bigg[\\text{log}\\ p_{\\theta}(x_{0}|x_{1:T}) \\ - \\\n\\text{log}\\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{1:T})}\\bigg]\n\\\\\n&=\\mathbb{E}_{q}\\biggl[\\text{log}\\ p_{\\theta}(x_{0}|x_{1:T}) \\ + \\ \\text{log}\\frac{p_{\\theta}(x_{1:T})}{q(x_{1:T}|x_{0})}\\biggr]\n\\\\\n&=\\mathbb{E}_{q}\\biggl[\\text{log}\\ \\frac{p_{\\theta}(x_{0}|x_{1:T}) \\ p_{\\theta}(x_{1:T})}{{q(x_{1:T}|x_{0})}}\\biggr]\n\\\\\n&=\\mathbb{E}_{q}\\biggl[\\text{log}\\frac{p_{\\theta}(x_{0:T})}{q(x_{1:T}|x_{0})}\\biggr] \\tag{7} \\\\\n\\end{align*}\n\\]\nThe maths above looks scary but if you look closely, we haven’t done anything fancy apart from applying standard definitions of expectation, KL-Divergence, and log to the original equation. Let’s denote equation (7) by \\({L}\\)\n\\[\n\\begin{align*}\n{L} &=\\mathbb{E}_{q}\\biggl[\\text{log}\\frac{p_{\\theta}(x_{0:T})}{q(x_{1:T}|x_{0})}\\biggr] \\\\\n&= \\mathbb{E}_{q}\\biggl[\\text{log}\\frac{p(x_{T})\\prod_{t=1}^T p_{\\theta}(x_{t-1}|x_{t})}{\\prod_{t=1}^T q(x_{t}|x_{t-1})}\\biggr] \\\\\n\\Rightarrow{L} &= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\underbrace{\\sum\\limits_{t=1}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t}|x_{t-1})}}\\biggr]\n\\end{align*}\n\\]\nUsing Bayes’ rule, we know that, \\[\n\\begin{align*}\nq(x_{t-1} | x_{t}, x_{0}) &= q(x_{t} | x_{t-1}, x_{0}) \\frac{q(x_{t-1}| x_{0})}{q(x_{t} | x_{0})} \\tag{8}\\\\\n{L} &= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\underbrace{\\sum\\limits_{t=1}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t}|x_{t-1})}}\\biggr] \\\\\n\\end{align*}\n\\]\nUsing (8) we can rewrite this as:\n\\[\\begin{align*}\nL &= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t}|x_{t-1})} \\ + \\ \\text{log}\\frac{p_{\\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})}\\biggr] \\\\\n\n&= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\text{log}\\frac{p_{\\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})} \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})}\\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n\n&= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\text{log}\\frac{p_{\\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})} \\ + \\ \\underbrace{\\sum\\limits_{t=2}^{T}\\text{log}\\bigl(q(x_{t-1}|x_{0})\\bigr) \\ - \\ \\text{log}\\bigl({q(x_{t}|x_{0})\\bigr)}} \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n\\end{align*}\\]\nExpanding that summation, we get:\n\\[\n\\begin{align*}\nL &= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\text{log}\\frac{p_{\\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})} \\ + \\ \\text{log}\\frac{q(x_{1} | x_{0})}{q(x_{T}|x_{0})} \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n&= \\mathbb{E}_{q}\\biggl[\\text{log}\\ p(x_{T}) \\ + \\ \\text{log }{p_{\\theta}(x_{0}|x_{1})\\ - \\ \\text{log }q(x_{1}|x_{0})} \\ + \\ \\text{log }q(x_{1} | x_{0}) \\ - \\ \\text{log }{q(x_{T}|x_{0})} \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n&= \\mathbb{E}_{q(x_{1:T}|x_{0})}\\biggl[\\text{log} \\frac{p(x_{T})}{q(x_{T}|x_{0})} \\ + \\ \\text{log }{p_{\\theta}(x_{0}|x_{1})} \\ + \\ \\sum\\limits_{t=2}^{T}\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n\\Rightarrow L &= \\mathbb{E}_{q(x_{1}|x_{0})}\\big[\\text{log }{p_{\\theta}(x_{0}|x_{1})}\\big] \\ + \\ \\mathbb{E}_{q(x_{T}|x_{0})}\\big[\\text{log }\\frac{p(x_{T})}{q(x_{T}|x_{0})}\\big] \\ + \\  \\sum\\limits_{t=2}^{T}\\mathbb{E}_{q(x_{t},\\ x_{t-1}|x_{0})}\\bigg[\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\tag{9}\\\\\n\\end{align*}\n\\] \nIn equation (9) we used linearity of expectation to expand the terms and rearranged the subscripts accordingly. This has provided us an opportunity to express the expression L in terms of KL-divergence. Let’s do that\n\\[\n\\begin{align*}\nL &= \\mathbb{E}_{q(x_{1}|x_{0})}\\big[\\text{log }{p_{\\theta}(x_{0}|x_{1})}\\big] \\ + \\ \\mathbb{E}_{q(x_{T}|x_{0})}\\big[\\text{log }\\frac{p(x_{T})}{q(x_{T}|x_{0})}\\big] \\ + \\  \\sum\\limits_{t=2}^{T}\\mathbb{E}_{q(x_{t},\\ x_{t-1}|x_{0})}\\bigg[\\text{log}\\frac{p_{\\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}\\biggr] \\\\\n\\Rightarrow L &= \\mathbb{E}_{q(x_{1}|x_{0})}\\big[\\text{log }{p_{\\theta}(x_{0}|x_{1})}\\big] \\ - \\ D_{KL}\\bigg(q(x_{T}|x_{0}) \\parallel \\ p(x_{T}) \\bigg) \\ - \\ \\sum\\limits_{t=2}^{T}\\mathbb{E}_{q(x_{t}|x_{0})}\\big[D_{KL}\\big(q(x_{t-1}|x_{t}, x_{0}) \\ \\parallel \\ p_{\\theta}(x_{t-1}|x_{t})\\big)\\big] \\tag{10} \\\\\n\\end{align*}\n\\]\nA few points to note about this equation:\n\nTake a look at the second term \\(D_{KL}\\big(q(x_{T}|x_{0}) \\parallel \\ p(x_{T})\\big)\\). The forward process represented by q is fixed. The term \\(p(x_{T})\\) is nothing but the end point of the forward process and the start of the reverse process, hence it is fixed as well. This means that we can safely ignore the second term in the optimization process.\nThe KL-divergence involved in the third term \\(D_{KL}\\big(q(x_{t-1}|x_{t}, x_{0}) \\ \\parallel \\ p_{\\theta}(x_{t-1}|x_{t})\\big)\\) is known as denoising matching term. We proved earlier that if \\(x_{0}\\) is known, we can show that the intermediate step in the forward process q are Gaussian (we will show it later). The reverse steps in p are also parameterized as Gaussian (check eq. (3)), hence we can say that the KL divergence term at each timestep is a comparison between two Gaussians. The term \\((q(x_{t-1}|x_{t}, x_{0})\\) also serves as the GT since it defines how to denoise a noisy image \\({x_{t}}\\) with access to what the final, completely denoised image \\(x_{0}\\) should be.\nAs a result of above two, we can rewrite our training objective as: \\[\nL = \\mathbb{E}_{q(x_{1}|x_{0})}\\big[\\text{log }{p_{\\theta}(x_{0}|x_{1})}\\big] \\ - \\ \\sum\\limits_{t=2}^{T}\\mathbb{E}_{q(x_{t}|x_{0})}\\big[D_{KL}\\big(q(x_{t-1}|x_{t}, x_{0}) \\ \\parallel \\ p_{\\theta}(x_{t-1}|x_{t})\\big)\\big] - C \\tag{11} \\\\\n\\]\n\n\nLet’s revisit equation (8) again now. We know that:\n\\[\n\\begin{align*}\nq(x_{t-1} | x_{t}, x_{0}) &= q(x_{t} | x_{t-1}, x_{0}) \\frac{q(x_{t-1}| x_{0})}{q(x_{t} | x_{0})}\n\\end{align*}\n\\] \nAs proved earlier, we can sample any arbritrary forward step given \\(x_{0}\\) as: \\[\nq(x_{t}\\vert x_{0}) = \\mathcal{N}(x_{t};\\sqrt{\\bar{\\alpha_{t}}} x_{0},\\ (1 - \\bar{\\alpha_{t}}) I)\n\\] \nCombining the above two facts, we can say that:\n\\[\n\\begin{align*}\nq(x_{t-1} | x_{t}, x_{0}) &= q(x_{t} | x_{t-1}, x_{0}) \\frac{q(x_{t-1}| x_{0})}{q(x_{t} | x_{0})} \\\\\n&= \\frac{\\mathcal{N}(x_{t};\\sqrt{\\bar{\\alpha_{t}}} x_{0},\\ (1 - \\alpha_{t}) \\ I) \\ \\ \\mathcal{N}(x_{t-1};\\sqrt{\\bar{\\alpha}_{t-1}} x_{0},\\ (1 - \\bar{\\alpha}_{t-1}) \\ I)}{\\mathcal{N}(x_{t};\\sqrt{\\bar{\\alpha_{t}}} x_{0},\\ (1 - \\bar{\\alpha_{t}}) \\ I)} \\\\\n&\\propto \\text{exp} \\bigg\\{-\\frac{1}{2}\\biggl[\n\\frac{(x_{t} - \\sqrt{\\alpha_{t}}x_{t-1})^2}{(1 \\ - \\ \\alpha_{t})} \\ + \\\n\\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}x_{0})^2}{(1 \\ - \\ \\bar{\\alpha}_{t-1})} \\ - \\\n\\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t}}x_{0})^2}{(1 \\ - \\ \\bar{\\alpha}_{t})}\n\\biggr]\\bigg\\} \\\\\n&= \\text{exp} \\bigg\\{-\\frac{1}{2}\\biggl[\n\\frac{(x_{t} - \\sqrt{\\alpha_{t}}x_{t-1})^2}{\\beta_{t}} \\ + \\\n\\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t-1}}x_{0})^2}{(1 \\ - \\ \\bar{\\alpha}_{t-1})} \\ - \\\n\\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t}}x_{0})^2}{(1 \\ - \\ \\bar{\\alpha}_{t})}\n\\biggr]\\bigg\\} \\\\\n&= \\text{exp} \\bigg\\{-\\frac{1}{2}\\biggl[\n\\frac{x_{t}^2 - 2\\sqrt{\\alpha_{t}}x_{t-1}x_{t} \\ + \\ \\alpha_{t}x_{t-1}^2}{\\beta_{t}} \\ + \\\n\\frac{x_{t-1}^2 - 2\\sqrt{\\bar{\\alpha}_{t-1}}x_{0}x_{t-1} \\ + \\ \\bar{\\alpha}_{t-1}x_{0}^2}{(1 \\ - \\ \\bar{\\alpha}_{t-1})} \\ - \\\n\\frac{(x_{t-1} - \\sqrt{\\bar{\\alpha}_{t}}x_{0})^2}{(1 \\ - \\ \\bar{\\alpha}_{t})}\n\\biggr]\\bigg\\} \\\\\n&= \\text{exp} \\bigg\\{-\\frac{1}{2}\\biggl[\n\\bigg(\\frac{\\alpha_{t}}{\\beta_{t}} \\ + \\ \\frac{1}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\\bigg) x_{t-1}^2 \\ - \\\n\\bigg(\\frac{2\\sqrt{\\alpha_{t}}\\ x_{t}}{\\beta_{t}} \\ + \\ \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}\\ x_{0}}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\\bigg) x_{t-1} \\ + \\ C(x_{t}, x_{0})\n\\biggr]\\bigg\\} \\tag{12} \\\\\n\\end{align*}\n\\] \nThe term \\(C(x_{t}, x_{0})\\) is some value computed using \\(x_{t}, x_{0}, \\text{and} \\ \\alpha\\), and doesn’t involve \\(x_{t-1}\\). Hence we treat it as a constant term w.r.t to \\(x_{t-1}\\). We know that in the case of a standard Gaussian, the density is proportional to:\n\\[\n\\begin{align*}\n&\\propto \\text{exp}\\big(- \\ \\frac{(x - \\mu)^2}{2\\sigma^2}\\big) \\\\\n&=\\text{exp}\\big(- \\frac{1}{2} \\frac{(x^2 \\ + \\ \\mu^2 \\ - \\ 2\\mu x)}{\\sigma^2}\\big) \\tag{13} \\\\\n\\end{align*}\n\\] \nComparing the coefficients of our Gaussian in (12) and the standard Gaussian in (13) we get:\n\\[\n\\begin{align*}\n\\tilde{\\beta_{t}} &=\n1 \\ \\big/ \\bigg(\\frac{\\alpha_{t}}{\\beta_{t}} \\ + \\ \\frac{1}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\\bigg) =\n\\frac{1- \\bar{\\alpha}_{t-1}}{1- \\bar{\\alpha}_t} \\beta_{t}\n= \\frac{(1- \\bar{\\alpha}_{t-1})(1 - \\alpha_{t})}{1 - \\bar{\\alpha}_{t}} \\tag{14} \\\\ \\\\ \\\\\n\\tilde{\\mu}(x_{t}, x_{0}) &=\n\\frac\n{\n\\dfrac{\\sqrt{\\alpha_{t}}\\ x_{t}}{\\beta_{t}} \\ + \\ \\dfrac{\\sqrt{\\bar{\\alpha}_{t-1}}\\ x_{0}}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\n}\n{\n\\dfrac{\\alpha_{t}}{\\beta_{t}} \\ + \\ \\dfrac{1}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\n} \\\\ \\\\\n&=\\dfrac{\\sqrt{\\alpha_{t}}\\ x_{t}}{\\beta_{t}} \\ + \\ \\dfrac{\\sqrt{\\bar{\\alpha}_{t-1}}\\ x_{0}}{1 \\ - \\ \\bar{\\alpha}_{t-1}} \\\\ \\\\\n&=\\bigg(\n\\dfrac{\\sqrt{\\alpha_{t}}\\ x_{t}}{\\beta_{t}} \\ + \\ \\dfrac{\\sqrt{\\bar{\\alpha}_{t-1}}\\ x_{0}}{1 \\ - \\ \\bar{\\alpha}_{t-1}}\n\\bigg)\n\\frac{1- \\bar{\\alpha}_{t-1}}{1- \\bar{\\alpha}_t} \\beta_{t} \\\\ \\\\\n\\Rightarrow \\tilde{\\mu}(x_{t}, x_{0}) &=\n\\frac{\\sqrt{\\alpha_{t}}(1- \\bar{\\alpha}_{t-1})}{1- \\bar{\\alpha}_{t}} x_{t} \\ + \\\n\\frac{\\sqrt{\\alpha_{t-1}}\\ \\beta_{t}}{1- \\bar{\\alpha}_{t}} x_{0} \\tag{15} \\\\\n\\end{align*}\n\\] \nWhen we applied the reparameterization trick, we learned that we can write: \\[\nx_{t} =  \\sqrt{\\bar{\\alpha_{t}}}x_{0} + \\sqrt{1 - \\bar{\\alpha_{t}}}\\epsilon_{t} \\\\\n\\]\nHence we can express (15) as:\n\\[\n\\begin{align*}\n\\Rightarrow \\tilde{\\mu}(x_{t}, x_{0}) &=\n\\frac{\\sqrt{\\alpha_{t}}(1- \\bar{\\alpha}_{t-1})}{1- \\bar{\\alpha}_{t}} x_{t} \\ + \\\n\\frac{\\sqrt{\\alpha_{t-1}}\\ \\beta_{t}}{1- \\bar{\\alpha}_{t}}\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} (x_{t} \\ - \\ \\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}\\epsilon_{t}) \\\\\n\\Rightarrow \\tilde{\\mu}(x_{t}, x_{0}) &=\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\ \\frac{\\beta_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{t}\\bigg)\n\\tag{16}\n\\\\ \\\\\n\\therefore \\ &q(x_{t-1} | x_{t}, x_{0}) \\sim \\mathcal {N}(x_{t-1}; \\tilde{\\mu}(x_{t}, x_{0}), \\ \\tilde{\\beta}\\bf{I})\n\\end{align*}\n\\]\nSo, \\(q(x_{t-1} | x_{t}, x_{0})\\) is the true distribution, and \\(\\tilde{\\mu}(x_{t}, x_{0}),\\text{, and } \\tilde{\\beta}\\) are the true parameters we are trying to approximate. Let’s talk about the other distriution \\(p_{\\theta}(x_{t-1}, x_{t})\\). Our model has to approximate the conditioned probability distributions in the reverse diffusion process:\n\\[\np_{\\theta}(x_{t-1}|x_{t}) := \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t))\n\\]\nThough we can try to learn both the mean and the variance of this distribution, the authors of the DDPMs paper found that learning the variance leads to lower quality samples. They decided to keep the variance \\(\\Sigma_{\\theta}(x_{t}, t)\\) to time specific constants. Hence our network is solely tasked with learning the mean \\(\\mu_{\\theta}(x_{t}, t)\\). The true mean that we are trying to approximate is:\n\\[\n\\begin{align*}\n\\tilde{\\mu}(x_{t}, x_{0}) &=\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\ \\frac{\\beta_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{t}\\bigg) =\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\ \\frac{1 \\ - \\ \\alpha_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{t}\\bigg)\n\\end{align*}\n\\]\n\\(x_{t}\\) will be available as an input during training. \\(\\alpha_{t}\\) is already known to us in advance (check the Reparameterization section), therefore we can reparameterize the Gaussian noise term instead to predict \\(\\epsilon_{t}\\) at a given timestep t as:\n\\[\n\\begin{align*}\n\\mu_{\\theta}(x_{t}, t) &=\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\ \\frac{1 \\ - \\ \\alpha_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{\\theta}(x_{t}, t)\\bigg) \\tag{17}\n\\end{align*}\n\\]\nLet’s recap of all the things we covered in the last section:\n\nWe showed that \\(q(x_{t-1} | x_{t}, x_{0})\\) is just a Gaussian, and that the KL-divergence at each timestep (for \\(t > 1\\)) between \\(q(x_{t-1} | x_{t}, x_{0})\\) and \\(p_{\\theta}(x_{t-1}|x_{t})\\) is KL-divergence between two Gaussian distributions\nDuring training, we have kept the variances of the reverse process to time-specific constants. Our only task is to learn to approximate the mean during training.\nWith reparameterization, we can instead learn to predict the noise at each timestep.\n\n\nLet’s revisit our objectve function now. Writing down the equation here: \\[\nL = \\mathbb{E}_{q(x_{1}|x_{0})}\\big[\\text{log }{p_{\\theta}(x_{0}|x_{1})}\\big] \\ - \\ \\sum\\limits_{t=2}^{T}\\mathbb{E}_{q(x_{t}|x_{0})}\\big[D_{KL}\\big(q(x_{t-1}|x_{t}, x_{0}) \\ \\parallel \\ p_{\\theta}(x_{t-1}|x_{t})\\big)\\big] \\ - C \\\\\n\\]\nWe know that the KL divergence between two Gaussian distributions can be evaluated in closed form (Check out this excellent post for more details). Also, the variance is fixed, and we only need to minimize the difference between the actual mean and the predicted mean.\n\\[\n\\begin{align*}\nL_{t\\sim U \\{ 2, T \\} } = \\mathbb{E}_{q}\\big[D_{KL}\\big(\n\\mathcal {N}(x_{t-1}; \\tilde{\\mu}(x_{t}, x_{0}), \\ \\tilde{\\beta}{I}) \\ \\parallel \\\n\\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t)\\big) \\big] \\\\\n\\end{align*}\n\\] \nFocusing on the KL divergence part: \\[\n\\begin{align*}\n&D_{KL}\\big(\n\\mathcal {N}(x_{t-1}; \\tilde{\\mu}(x_{t}, x_{0}), \\ \\tilde{\\beta}{I}) \\ \\parallel \\\n\\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_{t}, t), \\Sigma_{\\theta}(x_{t}, t)\\big)\n\\\\\n&=\n\\frac{1}{2} \\bigg[\\text{log}\\frac{\\bar{\\beta}}{\\Sigma_{\\theta}(x_{t}, t)} \\ - \\ d  \\ + \\\n\\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)^{T} \\Sigma_{\\theta}(x_{t}, t)^{-1} \\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)\\big)\\bigg]\\\\\n\\end{align*}\n\\]\nBecause variances are kept fixed, hence we can write it as:\n\\[\n\\begin{align*}\n&=\n\\frac{1}{2} \\bigg[\\text{log}\\frac{\\bar{\\beta}}{\\bar{\\beta}} \\ - \\ d  \\ + \\\n\\text{tr}\\big({\\bar{\\beta}^{-1} {\\bar{\\beta}}}\\big) \\ + \\\n\\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)^{T} \\bar{\\beta}^{-1} \\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)\\big)\\bigg]  \\ \\ \\ \\ \\\n\\\\\n&=\n\\frac{1}{2} \\bigg[\\text{log}1 \\ - \\ d  \\ + \\ d \\ + \\\n\\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)^{T} \\bar{\\beta}^{-1} \\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)\\big)\\bigg]\n\\\\\n&=\\frac{1}{2\\bar{\\beta}} \\bigg[\n\\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)^{T} \\big(\\bar\\mu(x_{t}, x_{0}) \\ - \\  \\mu_{\\theta}(x_{t}, t)\\big)\\big)\\bigg]\n\\end{align*}\n\\] \nNow that we have expanded the KL divergence, we can rewrite our loss function as: \n\\[\n\\begin{align*}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\nL_{t\\sim U \\{ 2, T \\} } &= \\mathbb{E}_{x_{0}, \\epsilon, t}\\bigg[\n\\dfrac{1}{2\\bar{\\beta}}\n\\norm{\\tilde{\\mu}_{\\theta}(x_{t}, x_{0})\\ - \\ \\mu_{\\theta}(x_{t}, t)}^2\n\\bigg] \\\\\n&=\\mathbb{E}_{x_{0}, \\epsilon, t}\\bigg[\n\\dfrac{1}{2 \\bar{\\beta}}\n\\norm{\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\\n\\frac{1 \\ - \\ \\alpha_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{t})\\bigg) \\ - \\\n\\frac{1}{\\sqrt{\\bar{\\alpha}}_{t}} \\bigg(x_{t} \\ - \\\n\\frac{1 \\ - \\ \\alpha_{t}}{\\sqrt{1 \\ - \\ \\bar{\\alpha}_{t}}}\\epsilon_{\\theta}(x_{t}, t)\\bigg)\n}^2\n\\bigg] \\\\\n&=\\mathbb{E}_{x_{0}, \\epsilon, t}\\bigg[\n\\underbrace{\\dfrac{(1 \\ - \\ \\alpha_{t})^2}{2 \\alpha_{t} (1 \\ - \\ \\alpha_{t})\\bar{\\beta}}}_{\\text{step-specific weighting}}\n\\norm{\\epsilon_t \\ - \\ \\epsilon_{\\theta}(x_{t}, t)}^2\n\\bigg] \\tag{18}\n\\end{align*}\n\\] \nA simpler version was also proposed by the authors, where they also discard this step-specific weigthing term. We can rewrite our final loss function as: \n\\[\n\\begin{align*}\nL^{simple} &= \\mathbb{E}_{x_{0}, \\epsilon, t}\\big[\n\\norm{\\epsilon_t \\ - \\ \\epsilon_{\\theta}(x_{t}, t)}^2\n\\big]\n\\end{align*}\n\\]\n The final objective function can be written as:  \\[\n\\begin{align*}\nL = L^{simple} \\  +  \\ C \\tag{19}\n\\end{align*}\n\\]\nwhere C is a constant not depending on \\(\\theta\\)\nThat’s it for now. I hope this notebook was enough to give you a solid understanding of the Diffusion models and the underlying maths. I tried to break down the maths as much as possible. In the next notebook, we will build a diffusion model in TF/Pytorch from scratch.\n\n\nReferences\n\nA Beginner’s Guide to Variational Methods\nFrom Autoencoder to Beta-VAE\nWhat are Diffusion Models?\nAri Seff’s tutorial\nDenoising Diffusion Probabilistic Models\nUnderstanding Diffusion Models\nAssembly AI: Intro to Diffusion Models\nKL Divergence between 2 Gaussian Distributions"
  },
  {
    "objectID": "posts/ddpms/part2/index.html",
    "href": "posts/ddpms/part2/index.html",
    "title": "All you need know about Gaussian distribution",
    "section": "",
    "text": "Today we will talk about the Gaussian Distribution and its importance in understanding the Denoising Diffusion Models or DDPMs for short.\nWe will cover the maths behind these concepts and will code them along the way. IMO the maths looks much scarier when presented in equations, but it becomes simple once you look at the code implementation. So, don’t be scared by the greek symbols used in the equations. Try to undersatnd the code. It will help you understand the concepts better. Also, most of the visualizations presented in this notebook are interactive. Without further ado, let’s start!\n\n1. Normal Distribution\nAlso known as Gaussian Distribution, the normal distribution is one of the most widely used continuous probability distributions. The notation, \\(\\mathcal{N}(\\mu, \\sigma^{2})\\) , is commonly used to refer to a normal distribution. The parameter \\(\\mu\\) represents the mean or expected value of the distribution, while the parameter \\(\\sigma\\) is its standard deviation. The variance of the distribution is \\(\\sigma^{2}\\)\nFor a real-valued random variable x, the probability density function is defined as: \\[\np(x; \\mu, \\sigma^{2}) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} exp({\\frac{-1}{2}(\\frac {x - \\mu}{\\sigma})^{2}}) \\tag {1}\n\\]\n\n\n\n2. Univariate Normal Distribution\nWhen we deal with only one random variable, e.g. x in the above equation, we call the distribution a univariate normal distribution. Let’s code up the above equation and take an example of a univariate normal distribution.\n\n\nShow the code\n\ndef get_univariate_normal(x, mu, sigma):\n    \"\"\"Generates a PDF for a Univariate Normal Distribution.\n\n    Args:\n        x: Vector of values sorted in ascending order\n        mu: Mean of the Gaussian\n        sigma: Standard Deviation of the Gaussian\n    Returns:\n        A PDF\n    \"\"\"\n    return 1 / (sigma * np.sqrt(2 * np.pi)) * (np.exp(-(x - mu)**2 / (2 * sigma**2)))\n\n\n# Mean of the distribution\nmu = 0.0\n\n# Standard deviation(SD for short)\nsigma = 1.0\n\n# Generate a linspace for a random variable x\nnum_samples = 100\nx = np.linspace(-3*sigma + mu, 3*sigma + mu, num=num_samples)\n\n# Plot the value against the PDF\nfig = go.Figure(\n    data=go.Scatter(\n        x=x,\n        y=get_univariate_normal(x, mu=mu, sigma=sigma),\n        line=dict(width=3,color=\"black\"),\n        fill=\"tonexty\",\n        fillcolor=\"skyblue\",\n    )\n)\n\nfig.add_annotation(x=mu, y=-0.001, text=\"Mean\",showarrow=True, arrowhead=2)\nfig.add_vline(x=mu, line_width=3, line_dash=\"dash\", line_color=\"green\")\nfig.update_layout(\n    {\n        \"title\": {\n            'text': f\"Univariate Gaussian Distribution <br> μ: {mu}, σ\\u00b2: {sigma**2}\",\n            'y':0.95,\n            'x':0.5,\n            'xanchor': 'center',\n            'yanchor': 'top',\n            'font': dict(size=14)\n        },\n        \"xaxis\": {\"title\": \"X\"},\n        \"yaxis\": {\"title\": \"Probability Density\"},\n        \"margin\": dict(l=0, r=0, b=0, t=50)\n    }\n)\n\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"univariate_normal_example.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"univariate_normal_example.png\"))\nfig.show()\n\n\n\nMoving the mean value shifts the distribution from right to left while changing sigma affects the shape of the distribution. As the value of sigma increases, the curve gets more and more flat. Let’s see that in action.\n\n\nShow the code\n\n# Random variable x\nx = np.linspace(-10.0, 10.0, 100)\n\n# Combination of mu and sigma. The first value\n# of any tuple represents mu while the second value\n# represents sigma here.\nmu_sigma_combos = [\n    [(0, 1), (-3, 1), (3, 1)],\n    [(0, 1), (0, 2), (0, 4)],\n]\n\n# Line colors and widths to be used\n# for different combinations\ncolors = [\"red\", \"black\", \"blue\"]\nwidths = [1, 2, 3]\nsubtitles = [\"Varying μ\", \"Varying σ\"]\n\n# Plot\n_, ax = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(12, 5), tight_layout=True)\nfor i, elem in enumerate(mu_sigma_combos):\n    legend = []\n    mus = set()\n    for j, comb in enumerate(elem):\n        mu, sigma = comb\n        mus.add(mu)\n        legend.append(f\"μ: {mu}, σ\\u00b2: {sigma**2}\")\n        ax[i].plot(x, get_univariate_normal(x, mu, sigma), linewidth=widths[j], c=colors[j])\n        ax[i].tick_params(labelbottom=True)\n    \n    ax[i].set_title(subtitles[i])\n    ax[i].legend(legend, loc=\"upper right\")\n    \n    for mu in mus:\n        ax[i].axvline(x=mu, color=\"green\", linestyle=\"--\")\n\nplt.suptitle(\"Univariate Normal Distribution\")\nplt.savefig(\n    os.path.join(SAVE_PLOT_DIR, \"univariate_with_dff_mu_sigma.png\"),\n    bbox_inches='tight'\n)\nplt.show()\n\n\n\n\n3. Multivariate Normal Distribution\nMultivariate normal distribution is the extension of univariate normal distribution to the case where we deal with a real-valued vector input instead of a single real-valued random variable. Like in the univariate case, the multivariate normal distribution has associated parameters \\(\\mu\\) representing the mean vector and \\(\\Sigma\\) representing the covariance matrix.\nThis is the probability density function for multivariate case: \\[\np(x; \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2} \\ \\vert{\\Sigma}\\vert^{1/2}} \\ exp \\ (\\frac{-1}{2}(x - \\mu)^T \\Sigma^{-1}(x - \\mu))  \\tag{2}\n\\]\n\nRandom Variable \\(X = [x_{1}, \\ x_{2}, \\ x_{3}...]\\) is a D-dimensional vector\nMean \\(\\mu = [\\mu_{1}, \\ \\mu_{2}, \\ \\mu_{3}...]\\) is a D-dimensional vector\nCovariance Matrix \\(\\Sigma\\) is a D X D dimensional matrix\n\nIf the vector X is 2-dimensional, then that distribution is also known as Bivariate Normal Distribution.\nNote: We need two dimensions to visualize a univariate Gaussian, and three dimensions to visualize a bivariate Gaussian. Hence for visualization purposes, we will show everything with a bivariate Gaussian, which then, can be extended to multivariate cases. Let’s visualize a bivariate Gaussian. We will use scipy.stats.multivariate_normal to generate the probability density.\n\n\nShow the code\n\ndef get_multivariate_normal(\n    mu,\n    cov,\n    sample=True,\n    sample_size=None,\n    seed=None,\n    gen_pdf=False,\n    pos=None\n):\n    \"\"\"Builds a multivariate Gaussian Distribution.\n    \n    Given the mean vector and the covariance matrix,\n    this function builds a multivariate Gaussian\n    distribution. You can sample from this distribution,\n    and generate probability density for given positions.\n    \n    Args:\n        mu: Mean vector representing the mean values for\n            the random variables\n        cov: Covariance Matrix\n        sample (bool): If sampling is required\n        sample_size: Only applicable if sampling is required.\n            Number of samples to extract from the distribution\n        seed: Random seed to be passed for distribution, and sampling\n        gen_pdf(bool): Whether to generate probability density\n        pos: Applicable only if density is generated. Values for which\n            density is generated\n    Returns:\n        1. A Multivariate distribution\n        2. Sampled data if `sample` is set to True else `None`\n        3. Probability Density if `gen_pdf` is set to True else `None`\n    \"\"\"\n    \n    # 1. Multivariate distribution from given mu and cov\n    dist = multivariate_normal(mean=mu, cov=cov, seed=seed)\n    \n    # 2. If sampling is required\n    if sample:\n        samples = dist.rvs(size=sample_size, random_state=seed)\n    else:\n        samples = None\n    \n    # 3. If density is required\n    if gen_pdf:\n        if pos is None:\n            raise ValueError(\"`pos` is required for generating density!\")\n        else:\n            pdf = dist.pdf(pos)\n    else:\n        pdf = None\n        \n    return dist, samples, pdf\n\n\n\n# Mean of the random variables X1 and X2\nmu_x1, mu_x2 = 0, 0\n\n# Standard deviation for the random variables X1 and X2\nsigma_x1, sigma_x2 = 1, 1\n\n# Positions for which probability density is\n# to be generated\nx1, x2 = np.mgrid[\n    (-3.0 * sigma_x1 + mu_x1):(3.0 * sigma_x1 + mu_x1): 0.1,\n    (-3.0 * sigma_x2 + mu_x2):(3.0 * sigma_x2 + mu_x2): 0.1\n]\npos = np.dstack((x1, x2))\n\n# Mean vector\nmu = [mu_x1, mu_x2]\n\n# Covariance between the two random variables\ncov_x1x2 = 0\n\n# Covariance Matrix for our bivariate Gaussian distribution\ncov = [[sigma_x1**2, cov_x1x2], [cov_x1x2, sigma_x2**2]]\n\n# Build distribution generate density\nsample = get_multivariate_normal(\n        mu=mu,\n        cov=cov,\n        sample=False,\n        seed=seed,\n        gen_pdf=True,\n        pos=pos\n    )\n\n\n# Plot the bivariate normal density\nfig = go.Figure(\n    go.Surface(\n        z=sample[2],\n        x=x1,\n        y=x2,\n        colorscale='Viridis',\n        showscale=False\n    )\n)\nfig.update_layout(\n    {\n        \"title\": dict(\n            text=\"Bivariate Distribution\",\n            y=0.95,\n            x=0.5,\n            xanchor=\"center\",\n            yanchor=\"top\",\n            font=dict(size=12)\n        ), \n        \"scene\":dict(\n            xaxis=dict(title='x1'),\n            yaxis=dict(title='x2'),\n            zaxis=dict(title='Probability density')\n        ),\n        \"xaxis\": dict(title=\"Values\"),\n        \"yaxis\": dict(title=\"Probability Density\"),\n    }\n)\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"bivariate_normal_example.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"bivariate_normal_example.png\"))\n\n\n\nThat’s an interactive plot. You can zoom in/out, and rotate the surface to see what the Gaussians look like. When you hover over the density, you will see black lines generating two univariate normals, one for x1 and another for x2\n\n\n4. Covariance\nIn the last section, we introduced the term covariance matrix. Before we move on to the next section, it is important to understand the concept of covariance. Let’s say X and Y are two random variables. Covariance of X and Y is defined as:\n\\[\nCov(X, Y) = E[(X - E(X))(Y - E(Y))] = E[XY] - E[X]E[Y]  \\tag{3}\n\\]\ni.e. the covariance is the expected value of the product of their deviations from their individual expected values.\nSo, what does covariance tell us? A lot…\n\nCovariance gives a sense of how much two random variables as well their scales are linearly related\nCovariance captures only linear dependence and gives no information about other kind of relationships\nIf the sign of the covariance is positive, then both variables tend to take on relatively high values simultaneously. If the sign of the covariance is negative, then one variable tends to take on a relatively high value at the times that the other takes on a relatively low value and vice versa.\nIf two variables X and Y are independent, then \\(Cov(X, Y)= 0\\) but the reverse isn’t true. Why? Because covariance doesn’t take into account non-linear relationships\n\n\n\n5. Covariance Matrix\nIf X is a N-dimensional vector i.e. \\(X = [x_{1}, \\ x_{2}, \\ x_{3}...x_{n}]\\), the covariance matrix is a NXN matrix defined as:\n\\[\n\\begin{bmatrix}\nCov(x_{1}x_{1}) & \\cdots & Cov(x_{1}x_{n}) \\\\\n\\vdots & \\ddots & \\vdots \\\\\nCov(x_{n}x_{1}) & \\cdots & Cov(x_{n}x_{n})\n\\end{bmatrix}\n\\]\nEach entry \\((i, j)\\) in this matrix defines the covariance of two random variables of the vector. Also:\n\\[\nCov(x_{i}x_{j}) = Var(x_{i}) \\ \\ \\ \\{ i=j\\}\n\\]\nLet’s take an example to showcase zero covariance, positive covariance, and negative covariance between two random variables x1 and x2\n\n\nShow the code\n\n# Mean of the random variables X1 and X2\nmu_x1, mu_x2 = 0, 0\n\n# Standard deviation of the random variables X1 and X2\nsigma_x1, sigma_x2 = 1, 1\n\n# Number of samples to extract\nsample_size = 2000\n\n# Positions for which probability density is\n# to be generated\nx1, x2 = np.mgrid[\n    (-3.0 * sigma_x1 + mu_x1):(3.0 * sigma_x1 + mu_x1): 0.1,\n    (-3.0 * sigma_x2 + mu_x2):(3.0 * sigma_x2 + mu_x2): 0.1\n]\npos = np.dstack((x1, x2))\n\n# Mean vector\nmu = [mu_x1, mu_x2]\n\n\n# Case 1: Zero Covariance\ncov_x1x2 = 0\nzero_cov = [[sigma_x1**2, cov_x1x2], [cov_x1x2, sigma_x2**2]]\n# Build distribution, sample and generate density\nzero_cov_res = get_multivariate_normal(\n        mu=mu,\n        cov=zero_cov,\n        sample=True,\n        sample_size=sample_size,\n        seed=seed,\n        gen_pdf=True,\n        pos=pos\n    )\n\n\n# Case 2: Positive Covarinace\ncov_x1x2 = 0.9\npos_cov = [[sigma_x1**2, cov_x1x2], [cov_x1x2, sigma_x2**2]]\n# Build distribution, sample and generate density\npos_cov_res = get_multivariate_normal(\n        mu=mu,\n        cov=pos_cov,\n        sample=True,\n        sample_size=sample_size,\n        seed=seed,\n        gen_pdf=True,\n        pos=pos\n    )\n\n\n# Case 3: Negative Covarinace\ncov_x1x2 = -0.9\nneg_cov = [[sigma_x1**2, cov_x1x2], [cov_x1x2, sigma_x2**2]]\n# Build distribution, sample and generate density\nneg_cov_res = get_multivariate_normal(\n        mu=mu,\n        cov=neg_cov,\n        sample=True,\n        sample_size=sample_size,\n        seed=seed,\n        gen_pdf=True,\n        pos=pos\n    )\n\n# Plot the covariances\n_, ax = plt.subplots(1, 3, figsize=(10, 4), sharex=True, sharey=True)\nsamples = [neg_cov_res[1], zero_cov_res[1], pos_cov_res[1]]\ntitles = [\"Negative Covariance\", \"Zero Covariance\", \"Positive Covariance\"]\n\nfor i in range(3):\n    ax[i].scatter(samples[i][:, 0], samples[i][:, 1], c=\"green\")\n    ax[i].set_xlabel(\"X1\")\n    ax[i].set_ylabel(\"X2\")\n    ax[i].set_title(titles[i])\n    ax[i].tick_params(labelleft=True)\n    ax[i].axvline(x=mu[0], color=\"blue\", linestyle=\"--\")\n    ax[i].axhline(y=mu[1], color=\"red\", linestyle=\"--\")\n\nplt.tight_layout()\nplt.savefig(os.path.join(SAVE_PLOT_DIR, \"covariance_pair_plot.png\"))\nplt.show()\n\n\nThe blue and red lines in the above plot represent the mean values of x1 and x2 respectively. Let’s visualize how the probability density surface changes with the covariance\n\n\nShow the code\n\nfig = go.Figure(\n    go.Surface(\n        z=neg_cov_res[2],\n        x=x1,\n        y=x2,\n        colorscale='Hot',\n        showscale=False\n    )\n)\nfig.update_layout(\n    {\n        \"title\": dict(\n            text=f\"Bivariate Distribution<br>cov_x1x2: {neg_cov[0][1]:.2f}\",\n            y=0.95,\n            x=0.5,\n            xanchor=\"center\",\n            yanchor=\"top\",\n            font=dict(size=12)\n        ), \n        \"scene\":dict(\n            xaxis=dict(title='X1'),\n            yaxis=dict(title='X2'),\n            zaxis=dict(title='Probability density')\n        ),\n        \"xaxis\": dict(title=\"Values\"),\n        \"yaxis\": dict(title=\"Probability Density\"),\n    }\n)\n\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"bivariate_negative_covariance_density.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"bivariate_negative_covariance_density.png\"))\nfig.show()\n\n\n\n\n\nShow the code\n\nfig = go.Figure(\n    go.Surface(\n        z=zero_cov_res[2],\n        x=x1,\n        y=x2,\n        colorscale='Viridis',\n        showscale=False\n    )\n)\nfig.update_layout(\n    {\n        \"title\": dict(\n            text=f\"Bivariate Distribution<br>cov_x1x2: {zero_cov[0][1]:.2f}\",\n            y=0.95,\n            x=0.5,\n            xanchor=\"center\",\n            yanchor=\"top\",\n            font=dict(size=12)\n        ), \n        \"scene\":dict(\n            xaxis=dict(title='X1'),\n            yaxis=dict(title='X2'),\n            zaxis=dict(title='Probability density')\n        ),\n        \"xaxis\": dict(title=\"Values\"),\n        \"yaxis\": dict(title=\"Probability Density\"),\n    }\n)\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"bivariate_zero_covariance_density.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"bivariate_zero_covariance_density.png\"))\nfig.show()\n\n\n\n\n\nShow the code\n\nfig = go.Figure(\n    go.Surface(\n        z=pos_cov_res[2],\n        x=x1,\n        y=x2,\n        showscale=False\n    )\n)\nfig.update_layout(\n    {\n        \"title\": dict(\n            text=f\"Bivariate Distribution<br>cov_x1x2: {pos_cov[0][1]:.2f}\",\n            y=0.95,\n            x=0.5,\n            xanchor=\"center\",\n            yanchor=\"top\",\n            font=dict(size=12)\n        ), \n        \"scene\":dict(\n            xaxis=dict(title='X1'),\n            yaxis=dict(title='X2'),\n            zaxis=dict(title='Probability density')\n        ),\n        \"xaxis\": dict(title=\"Values\"),\n        \"yaxis\": dict(title=\"Probability Density\"),\n    }\n)\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"bivariate_positive_covariance_density.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"bivariate_positive_covariance_density.png\"))\nfig.show()\n\n\n\nA few things to note in the above surface plots:\n\nThe plot with zero covariance is circular in every direction.\nThe plots with negative and positive covariances are more flattened on the 45-degree line, and are somewhat in a perpendicular direction to that line visually.\n\n\n\n6. Isotropic Gaussian\nAn isotropic Gaussian is one where the covariance matrix \\(\\Sigma\\) can be represented in this form: \\[\n\\Sigma = \\sigma^2 I  \\tag{4}\n\\]\n\n\\(I\\) is the Identity matrix\n\\(\\sigma^2\\) is the scalar variance\n\nQ: Why do we want to represent the covarince matrix in this form? A: As the dimensions of a multivariate Gaussian grows, the mean \\(\\mu\\) follows a linear growth where the covarince matrix \\(\\Sigma\\) follows quadratic growth in terms of number of parameters. This quadratic growth isn’t computation friendly. A diagonal covariance matrix makes things much easier\nA few things to note about isotropic Gaussian:\n\nEq. (4) represents a diagonal matrix multiplied by a scalar variance. This means that the variance along each dimension is equal. Hence an isotropic multivariate Gaussian is circular or spherical.\nWe discussed that Cov(x1, x2)=0 doesn’t mean x1 and x2 are independent but if the distribution is multivariate normal and Cov(x1, x2)=0, it implies that x1 and x2 are independent.\nIf the multivariate distribution is isotropic, that means: i. Covariance Matrix is diagonal ii. The distribution can be represented as a product of univariate Gaussians i.e. P(X) = P(x1)P(x2)..\n\nLet’s take an example of an isotropic normal\n\n\nShow the code\n\n# Mean of the random variables X1 and X2\nmu_x1, mu_x2 = 0, 0\n\n# Standard deviation of the random variables X1 and X2\n# Remember the std. is going to be the same\n# along all the dimensions.\nsigma_x1 = sigma_x2 = 2\n\n# Number of samples to extract\nsample_size = 5000\n\n# Positions for which probability density is\n# to be generated\nx1, x2 = np.mgrid[\n    (-3.0 * sigma_x1 + mu_x1):(3.0 * sigma_x1 + mu_x1): 0.1,\n    (-3.0 * sigma_x2 + mu_x2):(3.0 * sigma_x2 + mu_x2): 0.1\n]\npos = np.dstack((x1, x2))\n\n# Mean vector\nmu = [mu_x1, mu_x2]\n\n\n# Because the covariance matrix of an multivaraite isotropic\n# gaussian is a diagonal matrix, hence the covariance for \n# the dimension will be zero.\ncov_x1x2 = 0\ncov = [[sigma_x1**2, cov_x1x2], [cov_x1x2, sigma_x2**2]]\n\n\nisotropic_gaussian = get_multivariate_normal(\n                        mu=mu,\n                        cov=cov,\n                        sample=True,\n                        sample_size=sample_size,\n                        seed=seed,\n                        gen_pdf=True,\n                        pos=pos\n                    )\n\nfig = make_subplots(\n    rows=1, cols=2,\n    shared_yaxes=False,\n    shared_xaxes=False,\n    specs=[[{'type': 'scatter'}, {'type': 'surface'}]],\n    subplot_titles=(\n        \"Covariance x1_x2 = 0.0\",\n        f\"mu_x1: {mu_x1} sigma_x1: {sigma_x1**2} <br>mu_x2: {mu_x2} sigma_x2: {sigma_x2**2}\"\n    )\n)\n\n\nfig.add_trace(\n    go.Scatter(\n        x=isotropic_gaussian[1][:, 0],\n        y=isotropic_gaussian[1][:, 1],\n        mode='markers',\n        marker=dict(size=5, color=\"green\"),\n    ),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Surface(\n        z=isotropic_gaussian[2],\n        x=x1,\n        y=x2,\n        colorscale='RdBu',\n        showscale=False\n    ),\n    row=1, col=2\n)\n\nfig.update_layout(\n    {\n        \"scene\":dict(\n            xaxis=dict(title='X1'),\n            yaxis=dict(title='X2'),\n            zaxis=dict(title='Probability density')\n        ),\n        \"xaxis\": {\"title\": \"X1\"},\n        \"yaxis\": {\"title\": \"X2\"},\n        \"title\": {\"text\": \"Isotropic Gaussian\", \"x\":0.5, \"font\":dict(size=20)}\n    }\n)\n\nfig.write_html(os.path.join(SAVE_PLOT_DIR, \"isotropic_gaussian.html\"))\nfig.write_image(os.path.join(SAVE_PLOT_DIR, \"isotropic_gaussian.png\"))\n\n\n\n\n\n7. Conditional Distribution\nLet’s say we have a multivariate distribution over x where \\[\nx = \\begin{bmatrix}x_{1}\\\\x_{2}\\end{bmatrix} \\\\\n\\mu = \\begin{bmatrix}\\mu_{1}\\\\\\mu_{2}\\end{bmatrix} \\\\\n\\Sigma = \\begin{bmatrix}\\Sigma_{11} & \\Sigma_{12} \\\\ \\Sigma_{21} & \\Sigma_{22}\\end{bmatrix}\n\\]\nThen the distribution of x1 conditional on x2=a is multivariate normal:\n\\[\np(x1 | x2 = a) \\sim N(\\bar\\mu, \\bar\\Sigma) \\ \\ \\ \\text  {where:}\n\\]\n\\[\n\\bar\\mu = \\mu_{1} + \\ \\Sigma_{12}\\Sigma_{22}^{-1}(a - \\mu_{2}) \\tag{5}\n\\] \\[\n\\bar\\Sigma = \\Sigma_{11} - \\ \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21} \\tag{6}\n\\]\nBut why are we discussing the conditional distribution? Do you need to remember these equations?\nWell, first and foremost you don’t have to mug up any of these equations. You can find them easily on Wikipedia. But there is a reason why we are discussing the conditional distributions here. Let’s say you have a process that takes the form of a Markov Chain. For example, the forward process in Diffusion Models is one example of such a sequence. Let’s write down the equation for the same. \\[\nq(x_{1:T}\\vert x_{0}) := \\prod_{t=1}^{T}q(x_{t}\\vert x_{t-1}) :=\\prod_{t=1}^{T}\\mathcal{N}(x_{t};\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t}\\bf I) \\tag{7}\n\\]\nThis equation tells us a few things:\n\nThe forward process is a Markov Chain where the sample at the present step depends only on the sample at the previous timestep.\nThe covariance matrix is diagonal\nAt each timestep in this sequence, we gradually add Gaussian noise. But this isn’t very clear from the equation where is this addition taking place, right?\nThe term \\(\\beta\\) represents the variance at a particular timestep t such that \\(0 < \\beta_{1} < \\beta_{2} < \\beta_{3} < ... < \\beta_{T} < 1\\)\n\nTo understand the last point, let’s make some assumptions to simplify the eq (7). 1. We will ignore the variance schedule \\(\\beta\\) for now. We can rewrite the above equation as: \\[q(x_{1:T}\\vert x_{0}) := \\prod_{t=1}^{T}q(x_{t}\\vert x_{t-1}) :=\\prod_{t=1}^{T}\\mathcal{N}(x_{t}; x_{t-1},\\ \\bf I)  \\tag{8}\\] 2. We will consider x as a univariate normal. This assumption is made only to give readers a better understanding of the conditional Gaussian case. The same concept extends to multivariate normal.\nWith the above assumptions in mind, combined with the Law of total probability, we can write the equation as:\n\\[p(x_{t}) = \\int p(x_{t} \\vert \\ x_{t-1})p(x_{t-1})dx_{t-1} \\tag {9}\\]\nUsing (8), we can rewrite this as: \\[p(x_{t}) = \\int \\mathcal{N}(x_{t}; \\ x_{t-1}, 1) p(x_{t-1})dx_{t-1} \\tag {10}\\]\nBecause we are dealing with univariate normal, the identity matrix is nothing but a scalar value of 1. Moving forward, we can shift the terms in the above equation like this: \\[p(x_{t}) = \\int \\mathcal{N}(x_{t} - x_{t-1}; \\ 0, 1) p(x_{t-1})dx_{t-1} \\tag {11}\\]\nNotice two things that we got by this shift: 1. The mean and the variance values of the distribution on the right-hand side are 0 and 1 respectively. 2. If you look closely at the term on the RHS in the above equation, you will notice that it is the definition of convolution.\nCombining the above two facts, we can rewrite (11) as: \\[p(x_{t}) = \\mathcal{N}(0, 1) \\ * \\ p(x_{t-1}) \\tag {12}\\]\nProperty: The convolution of individual distributions of two or more random variables equals the sum of the random variables.\n\\[ \\Longrightarrow x_{t} = \\mathcal{N}(0, 1) \\ + \\ x_{t-1} \\tag {13}\\]\nWe will prove the above property in the next section, but this is one of the things that you should remember. Also, we hope that it is clear now why conditioned distributions in the forward process of Diffusion models are equivalent to “adding Gaussian noise” to previous timesteps. Don’t worry about the diffusion models related equations and terms like variance schedule. We will talk about them in detail in the upcoming notebooks.\n\n\n8. Convolution of probability distributions\nIn the last section we stated that the convolution of individual distributions of two or more random variables equals the sum of the random variables. To prove this, we will take an example of two normally distributed random variables X and Y. If X and Y are two normally distributed independent random variables such that\n\\[\nX \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^2) \\\\\nY \\sim \\mathcal{N}(\\mu_{2}, \\sigma_{2}^2) \\\\\n\\]\n\\(\\text{if} \\ Z = X + Y \\Longrightarrow Z \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2}, \\sigma_{1}^2 +\\sigma_{2}^2) \\tag{14}\\)\nOur goal is to prove that if we convolve the PDFs of X and Y, then the resulting distribution would be identical to the distribution of Z. Let’s write down the code for it.\n\n\nShow the code\n\n# Mean and Standard deviation of X\nmu_x = 0.0\nsigma_x = 2.0\n\n# Mean and Standard deviation of Y\nmu_y = 2.0\nsigma_y = 4.0\n\n# Mean and Standard deviation of Z\nmu_z = mu_x + mu_y\nsigma_z = np.sqrt(sigma_x**2 + sigma_y**2)\n\n# Get the distributions\ndist_x = norm(loc=mu_x, scale=sigma_x)\ndist_y = norm(loc=mu_y, scale=sigma_y)\ndist_z = norm(loc=mu_z, scale=sigma_z)\n\n# Generate the PDFs\nstep_size = 1e-4\npoints = np.arange(-30, 30, step_size)\n\npdf_x = dist_x.pdf(points)\npdf_y = dist_y.pdf(points)\npdf_z = dist_z.pdf(points)\n\n\n# NOTE: We cannot convolve over continous functions using `numpy.convolve(...)`\n# Hence we will discretize our PDFs into PMFs using the step size we defined above\npmf_x = pdf_x * step_size\npmf_y = pdf_y * step_size\n\n# Convolve the two PMFs\nconv_pmf = np.convolve(pmf_x, pmf_y, mode=\"same\")\nconv_pdf = conv_pmf / step_size\n\n\n# Let's plot the distributions now and check if we have gotten\n# the same distribution as Z. \n# NOTE: As we have approximated PMF from PDF, there would be\n# erros in the approximation. So, the final result may not\n# look 100% identical.\n\n_, ax = plt.subplots(1, 2, sharex=False, sharey=False, figsize=(12, 5))\n\nax[0].plot(points, pdf_x)\nax[0].plot(points, pdf_y)\nax[0].plot(points, pdf_z)\nax[0].set_title(\"Z = X + Y\")\nax[0].legend([\"PDF-X\", \"PDF-Y\", \"PDF-Z\"])\n\nax[1].plot(points, pdf_x)\nax[1].plot(points, pdf_y)\nax[1].plot(points, conv_pdf)\nax[1].set_title(\"Convolution of PDFs of X and Y\")\nax[1].legend([\"PDF-X\", \"PDF-Y\", \"Convolved\"])\n\nplt.savefig(os.path.join(SAVE_PLOT_DIR, \"convolution_of_pdfs.png\"))\nplt.show()\n\n\n\n\n9. The Forward Process\nThough we will talk about Diffusion Models in detail in the future posts as well, I will implement the forward process here to give you an idea that things that might look complicated in symbols aren’t that complicated in terms of code. Let’s rewrite the forward process equation again:\n\\[\nq(x_{1:T}\\vert x_{0}) := \\prod_{t=1}^{T}q(x_{t}\\vert x_{t-1}) :=\\prod_{t=1}^{T}\\mathcal{N}(x_{t};\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t}\\bf I)\n\\]\nTo implement the above equation:\n\nWe have to define the total number of timesteps T\nWe have to generate \\(\\beta_{t}\\) using a schedule. We can use any schedule including but not limited to linear, quadratic, etc. The only thing that we need to ensure is that \\(\\beta_{1} < \\beta_{2}...\\)\nSample a new image at timestep t from a conditional Gaussian for which the paramters are \\(\\mu_{t} = \\sqrt{1-\\beta_{t}} x_{t-1}\\) and \\(\\sigma_{t}^2 = \\beta_{t}\\)\nFor the last point, we can use the property(eq. (13)) we studied in the conditional distribution section. Hence we can write this as:\n\n\\[x_{t} \\sim (\\mathcal{N}(\\sqrt{1-\\beta_{t}} x_{t-1},\\ \\beta_{t}) + \\mathcal{N}(0, 1))\\]\n\\[\n\\Rightarrow x_{t} = \\sqrt{1-\\beta_{t}} x_{t-1} + \\sqrt{\\beta_{t}}\\epsilon \\ \\ ; \\ \\text{where} \\ \\epsilon \\sim \\mathcal{N}(0, 1) \\tag{15}\n\\]\nNow that we have broken down the equation in much simpler parts, let’s code it!\n\n\nShow the code\n\ndef forward_process_ddpms(img_t_minus_1, beta, t):\n    \"\"\"Implements the forward process of a DDPM model.\n    \n    Args:\n        img_t_minus_1: Image at the previous timestep (t - 1)\n        beta: Scheduled Variance\n        t: Current timestep\n    Returns:\n        Image obtained at current timestep\n    \"\"\"\n    \n    # 1. Obtain beta_t. Reshape it to have the same number of\n    # dimensions as our image array\n    beta_t = beta[t].reshape(-1, 1, 1)\n    \n    # 2. Calculate mean and variance\n    mu = np.sqrt((1.0 - beta_t)) * img_t_minus_1\n    sigma = np.sqrt(beta_t)\n    \n    # 3. Obtain image at timestep t using equation (15)\n    img_t = mu + sigma * np.random.randn(*img_t_minus_1.shape)\n    return img_t\n\n\n# Let's check if our forward process function is\n# doing what it is supposed to do on a sample image\n\n# 1. Load image using PIL (or any other library that you prefer)\nimg = Image.open(\"../images/cat.jpg\")\n\n# 2. Resize the image to desired dimensions\nIMG_SIZE = (128, 128)\nimg = img.resize(size=IMG_SIZE)\n\n# 3. Define number of timesteps\ntimesteps = 100\n\n# 4. Generate beta (variance schedule)\nbeta_start = 0.0001\nbeta_end = 0.05\nbeta = np.linspace(beta_start, beta_end, num=timesteps, dtype=np.float32)\n\n\nprocessed_images = []\nimg_t = np.asarray(img.copy(), dtype=np.float32) / 255.\n\n# 5. Run the forward process to obtain img after t timesteps\nfor t in range(timesteps):\n    img_t = forward_process_ddpms(img_t_minus_1=img_t, beta=beta, t=t)\n    if t%20==0 or t==timesteps - 1:\n        sample = (img_t.clip(0, 1) * 255.0).astype(np.uint8)\n        processed_images.append(sample)\n\n# 6. Plot and see samples at different timesteps\n_, ax = plt.subplots(1, len(processed_images), figsize=(15, 6))\n\nfor i, sample in enumerate(processed_images):\n    ax[i].imshow(sample)\n    ax[i].set_title(f\"Timestep: {i*20}\")\n    ax[i].axis(\"off\")\n    ax[i].grid(False)\n\nplt.suptitle(\"Forward process in DDPMs\", y=0.75)\nplt.savefig(os.path.join(SAVE_PLOT_DIR, \"forward_process.png\"))\nplt.show()\nplt.close()\n\n\nOne thing to note here is that as you increase the number of timesteps T, \\(\\beta_{t} \\to 1\\). At that point:\n\\[q(x_{T}) \\approx \\mathcal{N}(x_{T};\\ 0, I)\\]\nThat’s it for now. We will talk about reverse process and other things related to DDPMs in the future notebooks. I hope this notebook was enough to give you a solid understanding of Gaussian distribution and their usage in context of DDPMs.\n\n\nReferences\n\nWiki: Normal Distribution\nWiki: Multivariate Normal\nApplied Multivariate Statistical Analysis\nThe Gaussian Distribution\nNumpy docs on multivariate normal\nScipy statistics tutorial\nProbability and Information Theory\nGaussian Distribution and their properties\nThe Anisotropic Multivariate Normal Distribution\nPrimer on Gaussian\nGaussians\nIsotropic Gaussian\nIsotropic Gaussian\nWiki: Convolution of PDFs\nConvolvinf pdfs in Python\nAssembly AI: Intro to Diffusion Models\nAri Seff’s tutorial\nDenoising Diffusion Probabilistic Models"
  },
  {
    "objectID": "posts/ddpms/part1/index.html",
    "href": "posts/ddpms/part1/index.html",
    "title": "Fresher on Random Variables",
    "section": "",
    "text": "1. Random Variables\nThe study of probability (and most of statistics) revolves around “containers of information” that can hold different contents based on different associated events. These containers are called Random Variables (RV) and they can take up different values (any one at once, not combinations). Each event \\(E_i\\) (and hence, value) also has an associated probability \\(p_i\\) of happening.\nFor instance, suppose we roll a fair die once. Let’s call the result of the roll, \\(X\\). Here, \\(X\\) is a RV and it has 6 associated events for each face it can land on, and as a result, 6 possible values, depending on which event takes place. Upon rolling, we have ourselves left with an upward-oriented face with a number on it. \\(X\\) is now assigned this die value. The probably of each event is ⅙ (since we’re using a fair die) – there’s a 1 in 6 chance that any number will face upwards after the die has landed.\n\n1.1 Continuous Random Variables\nContinuous RVs can take in any float/real number (\\(\\mathbb{R}\\)) as a value based on the context. When filling up a bottle, your bottle can have 30.6ml or 56.89ml or 350.47ml of water in it, or the daily temperature can be 35ºC or 29.8ºC or 37.2ºC. It fluctuates and can take intermediate values. For some continuous RVs, there’s no range while others can be bounded.\n\n\n1.2 Discrete Random Variables\nThese usually fall into the category of integers (\\(\\mathbb{Z}\\)) that may or may not fall in a specific range in a specific context. Examples include the face value of a die when rolled, a card pulled from a deck, or letter grades on an exam like A, B, C, D, F. The similarity is that the collection of values from which they are sampled or pulled from are limited and finite. There is no “in-between” value (eg: you cannot get 5.5 on a die).\n\n\n\n2. Independence\nSuppose there are two events. If one does not affect the other, the two events are independent of each other. Though, what does “affect” mean in this context? It means the occurrence of one event does not impact the occurrence of the other. For instance, if I flip a fair coin 3 times, the second flip does not depend on the first flip, neither does the third flip on the second; in essence, the past outcome does not decide the future outcome. While there might be some causal link in the real world between events, in theory, we see the two events in isolation with each other, with no other factors involved.\nOn the other hand, dependent events impact the occurrence of one another. For example, if you misuse your vehicle on the road, there’s a higher probability of getting caught by the authorities as compared to using your vehicle appropriately. The occurrence of one event changes the probability of the other event occurring.\n\n\n3. Expectation\nWhen we flip a die several times (say, a large number like 1000), we’d like to know what is the average score we get at the end. The Expectation of a RV is a weighted sum of all possible values, weighted by the respective probabilities of occurrence. Ideally, for a die, each face value, 1 to 6, has probability \\(p_i = \\frac{1}{6}\\) of occuring. As such, the expectation or expected value of a RV is,\n\\[\n\\begin{align}\n    \\mathbb{E}(X) &= \\sum_{i} p_i \\cdot V_i\n\\end{align}\n\\]\nwhere \\(p_i\\) is the probability of event \\(E_i\\) taking place, and \\(V_i\\) is the value of said event. You may be wondering why this expectation is a float number that’s not a possible value. Since we’re looking at a simple average value and not the most occurring value, it makes sense to understand it as such. The expectation tells us what is the average face we get after flipping the die numerous times.\n\n\n4. Variance\nAs you flip the fair die, you probably won’t get the same value again and again – you’ll notice some deviation. The expected value of a fair die is 3.5. The maximum deviation of the die value in the long run is given the Variance. It’s always a positive number which represents how much the value of a RV deviates on either side of the expectation.\nIn fact, we’ve been using the term “deviation” a lot here. Surprisingly enough, variation is the square of the standard deviation \\(\\sigma\\) of a RV, i.e., \\(\\text{Var}(X) = \\sigma^2\\). The variance of a random variable \\(X\\) can be computed as follows:\n\\[\n\\begin{align}\n    \\text{Var}(X) &= \\mathbb{E}(X^2) + (\\mathbb{E}(X))^2 \\\\\n    &= \\mathbb{E}(X - \\mathbb{E}(X))^2\n\\end{align}    \n\\]\n\n\n5. Distributions\nRandom Variables have associated probabilities that dictate the chances of an event occurring. For a fair die, the probability is it’s \\(\\frac{1}{6}\\) and for a fair coin, it’s \\(\\frac{1}{2}\\). However, what is the characteristic of the random variable that shapes these probabilities?\nThis is given by the Distribution, a function that gives the probability of an event taking place. For some distributions, all events may have the same probability, while other distributions weight certains events more than others (causing some events to be more likely than others). There are a whole bunch of distributions that describe both synthetic and real world systems. Here are examples of some distributions:\n\n5.1 Uniform Distribution\nFor starters, let’s look at the Uniform Distribution. To represent a RV from a Uniform Distribution, we denote it as \\(X \\sim U(a, b)\\). This distribution has two parameters we need to supply – \\(a\\) and \\(b\\). They denote the bounds of the possible values the RV can assume. Here, the probability of any value occurring within this bound \\([a, b]\\) is equal. For example, if we have \\(X \\sim U(0, 1)\\), all the values inside that range (like 0.1, 0.2, 0.03, 0.023452) have an equal probability of occurring.\n\n\n5.2 Binomial Distribution\nIn many real-life applications, there’s this notion of failure or success associated with events. A random variable can hold the value of success or failure with a certain probability p of occurrence. The Binomial Distribution allows us to scale this single FAIL/PASS trial to many objects at once with replacement. To represent a RV from a Binomial Distribution, we denote it as \\(X \\sim \\text{Bin}(p, n)\\). We supply two parameters again: \\(p\\) is the probability of success and \\(n\\) is number of samples we are considering, each which can either be a success or failure.\nFor instance, at a factory, a certain machine part is manufactured without defects with probability 0.75. If the factory wants to test a bunch of samples for quality assurance, they can collect a sample of 100. Using this, we can answer questions like “What is the probability of 90 objects passing the defect test?” or “what is the probability of more than 10 objects failing the defect test?” and make changes to the process accordingly. Here, we’d say \\(X \\sim \\text{Bin}(0.75, 100)\\).\n\n\n5.3 Normal/Gaussian Distribution\nThis is important for the understanding of Diffusion Models. In the real world, everything isn’t as clearcut as FAIL/PASS. Neither do events all have the same probability of occurrence. There are some events that occur more often than others, making them statistically more probable than others. For example, in a sunny country like Singapore, the chances of a sunny day are much higher than the chances of a rainy day or cloudy day, ceteris paribus. The Normal Distribution helps us represent such events. To represent a RV from a Normal Distribution, we denote it as \\(X \\sim N(\\mu, \\sigma^2)\\). There are two parameters: \\(\\mu\\) is the average/mean/mode value the RV can take while \\(\\sigma\\) is the variance of the event (i.e., how spread away is it from this mean?).\nIn the next chapter, we cover the technical and implementation-specific details of the Normal Distribution and how it’s used in Diffusion Models."
  },
  {
    "objectID": "ddpms-series.html",
    "href": "ddpms-series.html",
    "title": "DDPMs from scratch",
    "section": "",
    "text": "DDPMs - Part 3\n\n\n\n\n\n\nSep 2, 2022\n\n\n18 min\n\n\n\n\n\n\n\n\n\nDDPMs - Part 2\n\n\n\n\n\n\nAug 3, 2022\n\n\n28 min\n\n\n\n\n\n\n\n\n\nDDPMs - Part 1 (Optional)\n\n\n\n\n\n\nAug 1, 2022\n\n\n6 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "DDPMs - Part 3\n\n\n\n\n\n\nSep 2, 2022\n\n\n\n\n\n\n\n\n\nDDPMs - Part 2\n\n\n\n\n\n\nAug 3, 2022\n\n\n\n\n\n\n\n\n\nDDPMs - Part 1 (Optional)\n\n\n\n\n\n\nAug 1, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Latent: Code the Maths",
    "section": "",
    "text": "If you are here, it is a testament that you are seeking to learn something new in the field of Data Science, Machine Learning, or Deep Learning. The field of Machine Learning moves fast. Almost a hundred papers are published daily on arXiv. The number of resources to learn from about these new developments is still low. For example, Diffusion Models saw exponential growth in terms of research papers and related experiments. We try to bridge that gap by putting the learning resources about new research in short blog posts. These blog posts consist of three things:\n\nConceptual theory\nUnderlying math\nCorresponding code\n\nWe are starting with the DDPMs series, but we may publish posts on new topics shortly. Check out the Blog and Archive sections on the top for details. The Resources section contains a few complementary resources. Feedback is always welcome!\n\nAbout us\n\n\n\n\n\nAakash Nain\n\nSenior Data Scientist at H2O.ai. One of the maintainers of the TensorFlow-addons package, Google Developers Expert in Machine Learning, and JAX. Actively contributes to Keras, TensorFlow, and JAX.\n\n\n\n\n\n\nSayak Paul\n\nML Engineer at Carted. Active contributor to Hugging Face Transformers, KerasCV and Keras. Off the work, he likes binge-watching stuff on Netflix.\n\n\n\n\n\n\nRishabh Anand\n\nUndergrad researcher from the National University of Singapore focusing on Graph Representation Learning for the natural sciences. Avid writer and active open-source contributor on AI/ML."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The Latent: Code the Maths",
    "section": "",
    "text": "A deeper dive into DDPMs\n\n\nDDPMs - Part 3\n\n\n\n\ndiffusion models\n\n\ngenerative modelling\n\n\ndeep learning\n\n\n \n\n\n\n\nSep 2, 2022\n\n\n18 min\n\n\n\n\n\n\n\n\nAll you need know about Gaussian distribution\n\n\nDDPMs - Part 2\n\n\n\n\ndiffusion models\n\n\ngenerative modelling\n\n\ndeep learning\n\n\n \n\n\n\n\nAug 3, 2022\n\n\n28 min\n\n\n\n\n\n\n\n\nFresher on Random Variables\n\n\nDDPMs - Part 1 (Optional)\n\n\n\n\nlinear algebra\n\n\ndiffusion models\n\n\n \n\n\n\n\nAug 1, 2022\n\n\n6 min\n\n\n\n\n\n\nNo matching items"
  }
]